{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. 문자 단위 RNN(Char RNN) - 더 많은 데이터\n",
    "\n",
    "이번 챕터에서는 더 많은 데이터 문자 단위 RNN을 구현합니다.\n",
    "\n",
    "## 2. 문자 단위 RNN(Char RNN)\n",
    "우선 필요한 도구들을 임포트합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 임의의 샘플을 만듭니다.\n",
    "\n",
    "### 1. 훈련 데이터 전처리하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합을 생성하고, 각 문자에 고유한 정수를 부여합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_set = list(set(sentence)) # 중복을 제거한 문자 집합 생성\n",
    "char_dic = {c: i for i, c in enumerate(char_set)} # 각 문자에 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 0, 'c': 1, ',': 2, 'g': 3, 'n': 4, 't': 5, 'a': 6, 's': 7, '.': 8, 'd': 9, ' ': 10, 'b': 11, 'l': 12, 'k': 13, 'p': 14, 'h': 15, 'i': 16, 'w': 17, 'f': 18, 'u': 19, 'o': 20, 'r': 21, 'm': 22, \"'\": 23, 'y': 24}\n"
     ]
    }
   ],
   "source": [
    "print(char_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 문자에 정수가 부여되었으며, 총 25개의 문자가 존재합니다. 문자 집합의 크기를 확인해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 25\n"
     ]
    }
   ],
   "source": [
    "dic_size = len(char_dic)\n",
    "print('문자 집합의 크기 : {}'.format(dic_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자 집합의 크기는 25이며, 입력을 원-핫 벡터로 사용할 것이므로 이는 매 시점마다 들어갈 입력의 크기이기도 합니다. 이제 하이퍼파라미터를 설정합니다. hidden_size(은닉 상태의 크기)를 입력의 크기와 동일하게 줬는데, 이는 사용자의 선택으로 다른 값을 줘도 무방합니다.\n",
    "\n",
    "그리고 sequence_length라는 변수를 선언했는데, 우리가 앞서 만든 샘플을 10개 단위로 끊어서 샘플을 만들 예정이기 때문입니다. 이는 뒤에서 더 자세히 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "hidden_size = dic_size\n",
    "sequence_length = 10  # 임의 숫자 지정\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 임의로 지정한 sequence_length 값인 10의 단위로 샘플들을 잘라서 데이터를 만드는 모습을 보여줍니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i+sequence_length]\n",
    "    y_str = sentence[i+1:i+sequence_length+1]\n",
    "    print(i, x_str, '->', y_str)\n",
    "    \n",
    "    x_data.append([char_dic[c] for c in x_str])\n",
    "    y_data.append([char_dic[c] for c in y_str])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 170개의 샘플이 생성되었습니다. 그리고 각 샘플의 각 문자들은 고유한 정수로 인코딩이 된 상태입니다. 첫번째 샘플의 입력 데이터와 레이블 데이터를 출력해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 18, 10, 24, 20, 19, 10, 17, 6, 4]\n",
      "[18, 10, 24, 20, 19, 10, 17, 6, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "print(x_data[0])\n",
    "print(y_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 칸씩 쉬프트 된 시퀀스가 정상적으로 출력되는 것을 볼 수 있습니다. 이제 입력 시퀀스에 대해서 원-핫 인코딩을 수행하고, 입력 데이터와 레이블 데이터를 텐서로 변환합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_one_hot = [np.eye(dic_size)[x] for x in x_data] # x 데이터는 원-핫 인코딩\n",
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 크기 : torch.Size([170, 10, 25])\n",
      "레이블의 크기 : torch.Size([170, 10])\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 크기 : {}'.format(X.shape))\n",
    "print('레이블의 크기 : {}'.format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩 된 결과를 보기 위해서 첫번째 샘플만 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 데이터의 첫번째 샘플도 출력해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 10, 24, 20, 19, 10, 17,  6,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 레이블 시퀀스는 f you want에 해당됩니다. 이제 모델을 설계합니다.\n",
    "\n",
    "### 2. 모델 구현하기\n",
    "모델은 앞서 실습한 문자 단위 RNN 챕터와 거의 동일합니다. 다만 이번에는 은닉층을 두 개 쌓을 겁니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layers):  # 현재 hidden_size는 dic_size와 같음.\n",
    "        super(Net, self).__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, num_layers=layers, batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(dic_size, hidden_size, 2) # 이번에는 층을 두 개 쌓습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.RNN() 안에 num_layers라는 인자를 사용합니다. 이는 은닉층을 몇 개 쌓을 것인지를 의미합니다. 모델 선언 시 layers라는 인자에 2를 전달하여 은닉층을 두 개 쌓습니다. 비용 함수와 옵티마이저를 선언합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([170, 10, 25])\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "print(outputs.shape) # 3차원 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(170, 10, 25)의 크기를 가지는데 각각 배치 차원, 시점(timesteps), 출력의 크기입니다. 나중에 정확도를 측정할 때는 이를 모두 펼쳐서 계산하게 되는데, 이때는 view를 사용하여 배치 차원과 시점 차원을 하나로 만듭니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1700, 25])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.view(-1, dic_size).shape) # 2차원 텐서로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([170, 10])\n",
      "torch.Size([1700])\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)\n",
    "print(Y.view(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 데이터는 (170, 10)의 크기를 가지는데, 마찬가지로 나중에 정확도를 측정할 때는 이걸 펼쳐서 계산할 예정입니다. 이 경우 (1700)의 크기를 가지게 됩니다. 이제 옵티마이저와 손실 함수를 정의합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppppp\n",
      "tttttttttttttttttttttwttttttttttttttttttttttttttttwttttttttttttttttttttttttwtttttttttwtttwrttttttttttttwtttttttttwtttttttttttttttttttttttttttttttttttttttttttttttttttttrttttttttttt\n",
      "  ssssssss so  sos s s sso sso sss s s so sos  so sos   s  so oosss s s  sso  so  sosossss  sso sos s sos sos so  ss o s s  ss   sosos o  so  soo  s o o   s sss  ss ss  s sosos so\n",
      "  kgh  tgmggmg.mggggmmggggm.ggggataggmmggg.g.g..gwg..mmgg..mg.mmgg.amggggmggg.ggmgmggggggg.mgggmt gggmmgg.ggm.m.mgggg.ggggmagggmmmg..m.gg.gmm.g.g.mmgg..mgggmgggg.mggggmamgggmmm.gg\n",
      "   t  et   t        t   t t t     t t                t                        t   t                 t     t     t   t t          t t          t   t   t   t                t       \n",
      "   m  tm   e e      e e dle e     e e      e d ee  e e e     e  e             e e   e e e    e ee e   e e e     e e e e e d  e d e d     e    e ele e e e   e e e    e  e ee e e e \n",
      "   t   t   d m tem  t tmeh, tme eeepe  , eeeme ee meme ,mme  ee mmm  tm   ,m  dme eet m e, e , mt e   m e d , em, e the em,  e  emme e,  re , t e e t e e t emtm, eree me e, e t t \n",
      "  ot eot eee , de,oee d e ehd d d dodhea  ehed dme dodh, eseeedd,ee ee  hd m hd e d ehe dm hd etded  ee ehdh, doehthdhehd ,seeeeeemehde   hd, dht emehthdhdhtmd , e tde,ddt, dede,h\n",
      " iat iat iitht i eththtot eotot totot i  tiimt tiioiotoa t mtiimihi mi   c et tot toe t t oiieitiit i thtotot toe tototot t miit thtot    iithtot ioe tototot t e t iiiiiiie titoe \n",
      " iat i   i ioetit t toeot eotot totot i  tmt t i ioiotoaoit e i ttii  o o   totoe toe t i  tiaiit t t eototot toe totot t ct iit tot tt   m eototoioe tot tot t e toiiitiiia titoe \n",
      "  t  t     toetoo t toto te toe e ao t t ttt eoeoto oeoeo ooeta a ho to  oa tttoe toe e tott   atoe t e eoto  toe toto  toaao  tt oeoiootot a to  t e aot e   to   t ti atta t to  \n",
      "  t  a t a t  oatototo       o  t a  tot doaoh tta   a e  to  a ottoott  tt u to  t     at tattoto  t to  t   wot  o     ooao  u to  at to  totoa t   t   e e a   rt th o oto oto  \n",
      "  t      t to  at t dot       e t s  t t doa   tta     t  to o   tt  t    t t toe t t    t ths  to  a t d d   aot  ot      to  e toe  t ata tot s t totos     t    t ah t  th  t   \n",
      "  to  to t doe ut t d d   t d e t t ,t t d a   tot   a tt th  a lt s t    t t dod't d    ttt so to  d t d d   tod t t   , sths e thd  t dta   t d t e d s     t u  t    t  thd t   \n",
      "  to lto t to   n t tot e t d e tot etot d a   t t s a    t      t   t    t t toeltot     ttos  tod t t d t   tot t t   er t s e t    t dt  l t dlt t s s t   t   n    tt  tod t   \n",
      "  to  t    to  tt t tot e t toe t t   ot d to  o ton e e  to  t  t   t    t t to 'tot      to   tog t tod t   tot d t d tn t d   t  o thglo   toe toe s d to  t   n  toe   toe s   \n",
      "  to  t  s to  en t t e e t ton t s e  tod to  o ton e eo to kt st   t    t t ton'tod e    to   tod t to  to  totot todoen tod t t e  thglo s toe toe s d eo  i      t e   toe s t \n",
      "  bo  to s toneoi t t e e d to  tos ee tod fo  eoton t  o to  t lt   to   t   ton'tod      to   tod e tod to  totot thdoe  tod   the  thglo s eon'doensod eo  i      in bf toe s i \n",
      "  tt  toes tontoi t thdhe d ton tod e  d e f nlfothg t e  to bt ltto to   t   tod'tod eii  toe  tod t tod ton wothi doi e  ton t i    t  lf l ton'toehtod eo  i  ei  i e f toeoe i \n",
      " gttf tons tonlei t tot e d do  toa e  d d f n'fns g t em torlo ltta to ' tm  tonstoto ii  toe  ton tetod ion'wothi t ihe  ton t i t  t nlf l tor'toe tod eo  t  eis ioe f toeot a \n",
      " gcof to s do 'ei   tot eet do  toa t  todce  't tonltnem to co lott ton' tos doe'totmeii ltotyetog tet d ton w toe t a enttoact aoen tonce l to 'toent d toe i  iis ioe o toeot a \n",
      " gtof to t do 'ea d tot ept d nltoa em toece ele tog t em to co lots ton  tos do 't a t i ltoey tog tet s ton w toe toanenttoaco toen togcf l to  toent d eo ii  uit i e   toemtua \n",
      " nton tandhto lui t tot emd t nctoa em todte n'e tog them to co lttu to   tnd ton t ao ii ltoe  to  t tod tnr w toa d a en toacoeaoem togcf l to  toemtod eoeii   is io tf toemt a \n",
      " nto  tandhto lui d tothemd dh ctoa em toece n'e tog them to co ltlt ton  tod won toa  im ltoe  ton e tod tor , toa toa en toacoetoem togcfll to  toemtod eoe i  ii  io tf toe t a \n",
      " nton tondhto bui d tothemd donltoa ea todce nleotoglthem to co lolt ton  tnd wonltoaosim dtoem ton e tod wo  , toa tot enstoaco them togcfll wo  toe tnd eo ii  un  io tf toe t a \n",
      "lntan tondhto bui d tothemd do ltoa em todceoele tonlthem to bo lolt ton  tod wo ltoarsim dtoem ton e tod wo  , toa t t em toach them togcfll to  toe tnd eo  i  ir  inetf toe t a \n",
      "lntan tonthwo bui d tot ep, donltot em todceonle to lthem to co lelt ton  tod wonltoar iisltoem toa e tod wor , toa t t tm toachethem togcflg eo  toe tnd eo ii  ir  ire f toe t a \n",
      "lntm  tant wo bui d tot ip, donltat em todceonle to lthem torco le t tor  tod wonltoer ii  toem toe e tod wor , tot tat em toach them togcfll eo  toe tnd ene i  ins i etf toe tia \n",
      "lnttn tant wo bui d toseep, donltaa um todce  le to lthem to colle t tor  tnd wonltoersig  toem tog e aod wo  , tot tat er toacoethem to co g eo  toe tnd e e i  irt iyetf toe tias\n",
      "lntt  tant wonbui d toship, don'taa ua tndce  le to lther to co le t won  tnd wonltoarsig  toe  to  e aod wo k, tht tat er toaco them to co g eo  the tnd e e t  irs iyetf the tiik\n",
      "lnton tant wonbui d toship, don'toa ua tn cennle sh  then to co le t won  tnd donltoamsig  toem to  , aod wonk,otut tather toact them ta co g wo  toe tnd en  ir ins tyecf the team\n",
      "lnson tont wonbut d toship, do 't ahum todce nlensh  then to co le t won  tnd don't arsig  them tos d aod don , tut tathey toach them to co g wor toe tnd e eiim irs tyeof the team\n",
      "lnson tant wonbui d toship, don't a um tadpe  le sh ether to co le t won  tnd donlt arsig  them tos t aod don , tut tat er toach them ta co g to  toe tod e  iimsert tyetf the teas\n",
      "lnson want donbui d toship, donlt a um uodpe ple sh ether ta co le t won  dod don't assig  them tos , aod donk, tut bather toach them to co g tor toe tnd e eiimmens tyetf the teas\n",
      "lrson tant wonbui d aoship, donlt a um up pe ple sh ether tanco lect won  tnd don't ass gn them toske aod donk, tut uather toach ther to co g to  toe end e eiimmendityetf the seis\n",
      "lrson want to bui d aoship, don't a um uadpenple to ether tonco lect won  and wo 't assign them toske aod tonk, tht sather taach ther torco g fo ktoe end e siim entityetf the seis\n",
      "lrson tant to build aoship, don't dhum uodpenple to ether tonco lect won  and wo 't assign them tos e aod wonk, bht wather toach ther torcong fo ktoe end e s im ensityetf the aeas\n",
      "lraon tant to build toship, do 't d um to penplento ether tor'ollect won  and wo 't ass gn them taske aod work, but bather toach ther torcong fo ktoe end e siimmentity tf the aeas\n",
      "lraon tant wo build anship, do 't dhum ao people to ether to collect won  and wo 't assign them taske aod work, but wather toach ther torcong fo  the end e s im entity tf the aeas\n",
      "lraon want aorluild anship, don't d um up people tog ther torcollect wan  and wo 't assign them tasks aod work, but rather toach them torcong for toe end e s immentity tf the aeas\n",
      "lrson want wopbuild a ship, don't dhum up people together toncollect wang and wo 't assign them tasks aod work, but rather toach them torcong for the end e s immensity of the eeas\n",
      "lrson want wo buuld a ship, don't dhum up people together toncollect woog and do 't assign them toskt aod dork, but rather teach them torlong fo  the end e s imsensity of the aeas\n",
      "lrson want wo build anship, don't dhum up people together torcollect woo  and do 't assign them toskt and dork, but rather toach them torlong for toe end ess immensity of the seas\n",
      "lrsoo want wo build anship, don't drum uo people together togcollect wood and don't assign them tosks aod dork, but rather thach them torlong for toe end ess immensity of the eead\n",
      "lrson want to build a ship, don't drum up people together to collect wood and don't assign them tosks aod dork, but rather toach them torlong for toe end ess immensity of the eead\n",
      "lrson want to build anship, don't drum up people together to lollect wood and won't assign them tosks and work, but rather toach them torlond for toe endlems immensity of the eeas\n",
      "prson want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather thach them torlong for toe endless immensity of the eead\n",
      "prsoo want wo build anship, don't drum up people to ether to lollect wood and won't assign them tasks and work, but rather toach them torlond for toe endless immensity of the eead\n",
      "lrsoo want wo build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long fo  toe endless immensity of the eeas\n",
      "lmaoo want wo build a ship, don't d um up people to ether to collect wood and won't assign them tasks and work, but rather teach them torlong for toe endless immensity of the eeas\n",
      "lmaou want wo build a ship, don't drum up people together to collect wood and won't assign them tasks and dork, but rather teach them to bond for toe endless immensity of the eead\n",
      "grsor want fo build aoship, don't drum up people together to collect wood and don't assign them tasks and dork, but rather thach them to long for the endless immensity of the ehas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grsor want to build aoship, don't drum up people to ether to collect wood and don't assign them tasks and dork, but rather toach them to long for the endless immensity of the eead\n",
      "graor want to build aoship, don't drum up people to ether to collect wood and don't assign them tasks and dork, but bather toach them to long for the endless immensity of the eead\n",
      "grsou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and dork, but rather thach them to long for the endless immensity of the eead\n",
      "grsou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and dork, bet rather teach them to long for the endless immensity of the sead\n",
      "prsou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and dork, bet rather toach them to long for the endless immensity of the eead\n",
      "prsou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the eead\n",
      "prsou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sead\n",
      "prsou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the seak\n",
      "lrbou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the seac\n",
      "lrbou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seac\n",
      "lrbou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and dork, but rather teach them to long for the endless immensity of the sead\n",
      "lrbou want to build a ship, don't drum up people to ether to collect wood and don't assign them tasks and dork, but rather teach them to long for the endless immensity of the seak\n",
      "lraou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seak\n",
      "poeou want to build a ship, don't drum up people to ether to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sead\n",
      "poeou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sead\n",
      "p eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the seac\n",
      "poeou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the seac\n",
      "lreou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "l eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them ta long for the endless immensity of the seak\n",
      "l eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "l eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "l bou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "l bou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the seak\n",
      "l bou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the sndless immensity of the seak\n",
      "l aou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "l eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the seac\n",
      "f eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "f eou want to build a ship, don't drum up people together to collect wood and won't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g eou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p tou want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "p you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "t you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "g you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X) # (170, 10, 25) 크기를 가진 텐서를 매 에포크마다 모델의 입력으로 사용\n",
    "    loss = criterion(outputs.view(-1, dic_size), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "     # results의 텐서 크기는 (170, 10)\n",
    "    results = outputs.argmax(dim=2)\n",
    "    predict_str = \"\"\n",
    "    \n",
    "    for j, result in enumerate(results):\n",
    "        if j == 0: # 처음에는 예측 결과를 전부 가져오지만\n",
    "            predict_str += ''.join([char_set[t] for t in result])\n",
    "        else: # 그 다음에는 마지막 글자만 반복 추가\n",
    "            predict_str += char_set[result[-1]]\n",
    "    print(predict_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 이상한 예측을 하지만 마지막 에포크에서는 꽤 정확한 문자을 생성하는 것을 볼 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3, 10, 24, 20, 19, 10, 17,  6,  4,  5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0] # 첫번재 배치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([170, 10])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
